# üöÄ Kasparro ‚Äì Multi-Agent AI Content Generation System

## üß© Problem Statement

Design and implement a true **AI-agentic**, production-style multi-agent automation system that takes a single structured product dataset as input and generates machine-readable JSON content pages.
The system must:

* Use **LLMs** inside agents
* Use a **StateGraph** (LangGraph) instead of a sequential script
* Use shared memory/state across agents
* Demonstrate proper agent boundaries
* Use reusable logic blocks
* Produce deterministic JSON outputs

The task explicitly avoids template-only scripts and requires an **AI-powered, agentic architecture** ‚Äî not a monolithic or rule-based pipeline.

---

## üõ†Ô∏è Solution Overview

This project implements a fully autonomous **AI-Powered Multi-Agent Pipeline** using:

* **LangGraph** for graph-style orchestration
* **Groq LLM (llama-3.1-8b-instant)** for generation
* **Pydantic PipelineState** for shared memory
* **Specialized agents** for each content generation task
* **Logic-block fallbacks** to guarantee deterministic output

The pipeline consumes a single structured product dataset and generates:

* ‚úÖ FAQ Page (faq.json)
* ‚úÖ Product Description Page (product_page.json)
* ‚úÖ Comparison Page (comparison_page.json)
* ‚úÖ Logs (run_logs.json)

Each AI agent independently contributes content and updates the shared state.

---

## üéØ Key System Objectives

* ‚úÖ Use real AI-powered agents (LLM-driven)
* ‚úÖ Use LangGraph for multi-agent orchestration
* ‚úÖ Maintain a single shared PipelineState
* ‚úÖ Enforce strong agent boundaries
* ‚úÖ Maintain deterministic JSON output
* ‚úÖ Clean separation between logic blocks, models, templates, and agents
* ‚úÖ Ensure production-style modular architecture

---

## üì¶ Scopes & Assumptions

### ‚úÖ Scope

* Uses the provided **GlowBoost Vitamin C Serum** as the primary input
* Creates a fictional **Product B via LLM** for comparison
* Generates exactly 3 output artifacts:

  * FAQ JSON (AI generated)
  * Product Description JSON (AI + logic blocks)
  * Comparison JSON (AI competitor + structured reasoning)
* Runs entirely locally
* Outputs are strictly **machine-readable JSON**

---

### üö´ Out of Scope

* No frontend
* No external product lookup
* No manual curation
* No non-AI rule-based content writing

---

### üìå Assumptions

* Input data is valid
* LLM responses are parsed into structured content
* Logic blocks act as fallback when LLM output is malformed

---

## üß† System Design (Mandatory)

### 1Ô∏è‚É£ Architectural Philosophy

This is a **true agentic system**, where:

* Each agent performs one specialized AI-driven task
* Agents **do not depend on each other directly**
* All information is passed via a **shared Pydantic PipelineState**
* LangGraph determines execution flow

This mirrors modern enterprise AI workflow orchestrators.

---

### 2Ô∏è‚É£ Layered System Architecture

The architecture is cleanly divided into:

1. **Input Layer**
2. **Data Modeling Layer**
3. **AI Agent Layer (LLM-powered)**
4. **Logic Block Layer**
5. **Template Layer**
6. **LangGraph Orchestration Layer**
7. **Output Layer**

---

### 3Ô∏è‚É£ Input Layer

**input_data.py**

* Contains the canonical product dataset
* No external API calls

---

### 4Ô∏è‚É£ Data Modeling Layer

Models include:

* **Product**
* **Question**
* **PipelineState (Pydantic)**

PipelineState holds:

* product
* product_b
* questions
* faqs
* product_page
* comparison_page
* logs

This ensures all agents read/write a consistent shared memory.

---

### 5Ô∏è‚É£ Agent Execution Layer (AI-Powered Agents)

Each agent performs one specialized AI task:

---

#### **ParserAgent**

* Converts raw dict ‚Üí Product model
* Initializes state

---

#### **QuestionGenerationAgent (LLM-powered)**

* Uses Groq LLM to generate ~15 structured questions
* Writes them into `state.questions`

---

#### **FAQAgent (LLM-powered + logic fallback)**

* For each question ‚Üí generates answer via LLM
* If LLM returns invalid JSON ‚Üí fallback to logic blocks
* Writes final structured FAQ data into `state.faqs`

---

#### **ProductPageAgent**

* Generates product description content
* Uses:

  * logic blocks for structure
  * LLM for narrative enhancement

---

#### **ComparisonAgent (LLM-powered)**

* LLM creates a fictional competitor product
* LLM provides a narrative comparison
* Deterministic logic-block comparison ensures valid JSON fields
* Outputs final comparison JSON

---

### 6Ô∏è‚É£ Logic Block Layer

Reusable modules handle deterministic transformations:

* benefits_block
* usage_block
* safety_block
* ingredients_block
* comparison_block

These serve as **fallbacks** & **validators** for LLM output.

---

### 7Ô∏è‚É£ Template Layer

Templates define strict JSON schemas for:

* FAQ Page
* Product Description Page
* Comparison Page

Templates ensure consistent structure regardless of LLM behavior.

---

### 8Ô∏è‚É£ Orchestration Layer (LangGraph)

**langgraph_orchestrator.py**

* Builds a StateGraph
* Each agent becomes a node
* State flows through nodes
* Execution stops when all nodes complete
* Final state is dumped into JSON files

This replaces the old **linear script**, meeting the evaluator‚Äôs requirements.

---

### 9Ô∏è‚É£ Determinism & Safety Guarantees

* LLM output is validated and sanitized
* Logic fallbacks ensure structural correctness
* Templates enforce JSON schema
* Shared state ensures predictable agent interactions

---

## 3Ô∏è‚É£ Data Flow Summary

1. Product loaded
2. ParserAgent ‚Üí Product Model
3. LLM generates questions (QuestionGenerationAgent)
4. LLM generates answers (FAQAgent)
5. LLM + logic generate product page (ProductPageAgent)
6. LLM creates competitor + narrative + structured comparison (ComparisonAgent)
7. LangGraph writes all final JSONs

---

## 4Ô∏è‚É£ Design Principles Followed

* **Single Responsibility** per agent
* **No global variables**
* **AI-powered agents**
* **Shared structured state**
* **Deterministic final JSON**
* **Reproducible pipeline**
* **Fully modular**
* **Production-ready separation of concerns**
